---
title: "Untitled"
format: html
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.patches import Rectangle
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')
```

```{python}
PROJECT_ROOT = Path().resolve()
PROJECT_ROOT = PROJECT_ROOT.parents[1]
PRED_DIR = PROJECT_ROOT / 'Output' / 'Model Run' / 'Merged' / 'model_predictions.csv'
OUTPUT_DIR = PROJECT_ROOT / 'Output' / 'Figures' / 'Temporal Analysis'
```

```{python}
predictions_df = pd.read_csv(PRED_DIR)
predictions_df['Date'] = pd.to_datetime(predictions_df['Date'])
predictions_df['Year'] = predictions_df['Date'].dt.year
predictions_df['Month'] = predictions_df['Date'].dt.month
predictions_df['YearMonth'] = predictions_df['Date'].dt.to_period('M')
```

```{python}
# Extract month
predictions_df['Month'] = predictions_df['Date'].dt.month

FIRE_SEASON = [4, 5, 6, 7, 8, 9] 
NON_FIRE_SEASON = [10, 11, 12, 1, 2, 3]  

predictions_df['Season'] = predictions_df['Month'].apply(
    lambda m: 'Fire Season' if m in FIRE_SEASON else 'Non-Fire Season'
)

MODELS_TO_ANALYZE = ['Standard', 'Seq21', 'Seq7', 'Reduced']
```

```{python}
fire_season_df = predictions_df[predictions_df['Season'] == 'Fire Season'].copy()
non_fire_season_df = predictions_df[predictions_df['Season'] == 'Non-Fire Season'].copy()

print("Data Split by Season:")
print(f"   Fire Season:     {len(fire_season_df):>8,} records ({len(fire_season_df)/len(predictions_df)*100:>5.1f}%)")
print(f"   Non-Fire Season: {len(non_fire_season_df):>8,} records ({len(non_fire_season_df)/len(predictions_df)*100:>5.1f}%)")
print()

# Fire occurrence by season
fire_season_fires = fire_season_df['Fire_occurred'].sum()
non_fire_season_fires = non_fire_season_df['Fire_occurred'].sum()
total_fires = predictions_df['Fire_occurred'].sum()

print("Fire Occurrences by Season:")
print(f"   Fire Season:     {int(fire_season_fires):>6,} fires ({fire_season_fires/len(fire_season_df)*100:>5.2f}% of records, {fire_season_fires/total_fires*100:>5.1f}% of total fires)")
print(f"   Non-Fire Season: {int(non_fire_season_fires):>6,} fires ({non_fire_season_fires/len(non_fire_season_df)*100:>5.2f}% of records, {non_fire_season_fires/total_fires*100:>5.1f}% of total fires)")
print(f"   Total:           {int(total_fires):>6,} fires")
print()
```

```{python}
## compute confusion matrix

results = {
    'Fire Season': {},
    'Non-Fire Season': {}
}

for season_name, season_df in [('Fire Season', fire_season_df), 
                                ('Non-Fire Season', non_fire_season_df)]:
    print(f"\n{season_name}:")
    print("-" * 80)
    
    y_true = season_df['Fire_occurred'].values
    
    for model_name in MODELS_TO_ANALYZE:
        pred_col = f'{model_name}_pred'
        y_pred = season_df[pred_col].values
        

        cm = confusion_matrix(y_true, y_pred)
        
        # Store results
        results[season_name][model_name] = {
            'cm': cm,
            'y_true': y_true,
            'y_pred': y_pred
        }
        
        # Print summary
        tn, fp, fn, tp = cm.ravel()
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"\n   {model_name}:")
        print(f"      TN={tn:>7,}  FP={fp:>7,}  FN={fn:>7,}  TP={tp:>7,}")
        print(f"      Acc={accuracy:.4f}  Prec={precision:.4f}  Rec={recall:.4f}  F1={f1:.4f}")

print("\n")
```



```{python}
# ============================================================================
# 9. Create Comparison Table by Season
# ============================================================================

comparison_data = []

for season_name in ['Fire Season', 'Non-Fire Season']:
    for model_name in MODELS_TO_ANALYZE:
        cm = results[season_name][model_name]['cm']
        tn, fp, fn, tp = cm.ravel()
        
        total = tn + fp + fn + tp
        accuracy = (tp + tn) / total
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        comparison_data.append({
            'Season': season_name,
            'Model': model_name,
            'TN': tn,
            'FP': fp,
            'FN': fn,
            'TP': tp,
            'Accuracy': accuracy,
            'Precision': precision,
            'Recall': recall,
            'Specificity': specificity,
            'F1-Score': f1
        })

comparison_df = pd.DataFrame(comparison_data)

# Print by season
for season_name in ['Fire Season', 'Non-Fire Season']:
    print(f"\n{season_name}:")
    print("="*100)
    season_data = comparison_df[comparison_df['Season'] == season_name]
    print(season_data[['Model', 'TN', 'FP', 'FN', 'TP']].to_string(index=False))
    print()
    print(season_data[['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score']].to_string(index=False))
    print()

# Save comparison table
comparison_file = OUTPUT_DIR / 'confusion_matrix_comparison_by_season.csv'
comparison_df.to_csv(comparison_file, index=False)
print(f"Comparison table saved to: {comparison_file}\n")
```

```{python}
# Prepare data for ploting
metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
axes = axes.flatten()

for idx, metric in enumerate(metrics_to_plot):
    ax = axes[idx]
    
    # Prepare data
    fire_season_data = comparison_df[comparison_df['Season'] == 'Fire Season']
    non_fire_season_data = comparison_df[comparison_df['Season'] == 'Non-Fire Season']
    
    x = np.arange(len(MODELS_TO_ANALYZE))
    width = 0.35
    
    # Plot bars
    bars1 = ax.bar(x - width/2, fire_season_data[metric], width, 
                   label='Fire Season', color='#ff6b6b', alpha=0.8)
    bars2 = ax.bar(x + width/2, non_fire_season_data[metric], width, 
                   label='Non-Fire Season', color='#4ecdc4', alpha=0.8)
    
    
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}',
                   ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax.set_xlabel('Model', fontsize=12, fontweight='bold')
    ax.set_ylabel(metric, fontsize=12, fontweight='bold')
    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold', pad=15)
    ax.set_xticks(x)
    ax.set_xticklabels(MODELS_TO_ANALYZE, fontsize=11)
    ax.legend(fontsize=11, loc='best')
    ax.grid(axis='y', alpha=0.3)
    ax.set_ylim(0, 1.1)

plt.suptitle('Model Performance Comparison: Fire Season vs Non-Fire Season', 
             fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout()

plt.show()
```

```{python}
def calculate_pr_metrics(y_true, y_pred):
    """Calculate Precision, Recall, F1"""
    tp = ((y_true == 1) & (y_pred == 1)).sum()
    fp = ((y_true == 0) & (y_pred == 1)).sum()
    fn = ((y_true == 1) & (y_pred == 0)).sum()
    tn = ((y_true == 0) & (y_pred == 0)).sum()
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'TP': int(tp),
        'FP': int(fp),
        'FN': int(fn),
        'TN': int(tn),
        'Precision': precision,
        'Recall': recall,
        'F1': f1
    }

# Aggregate by month
monthly_metrics = []

for year_month in sorted(predictions_df['YearMonth'].unique()):
    month_data = predictions_df[predictions_df['YearMonth'] == year_month].copy()
    
    # Count fires
    total_fires = (month_data['Fire_occurred'] > 0).sum()
    total_records = len(month_data)
    fire_rate = total_fires / total_records
    
    # Get month info
    date = month_data['Date'].min()
    year = date.year
    month = date.month
    
    # Base metrics
    metrics = {
        'YearMonth': year_month,
        'Date': date,
        'Year': year,
        'Month': month,
        'Total_Records': total_records,
        'Total_Fires': int(total_fires),
        'Fire_Rate': fire_rate
    }
    
    # Calculate for each model
    for model_name in MODELS_TO_ANALYZE:
        pred_col = f'{model_name}_pred'
        
        model_metrics = calculate_pr_metrics(
            month_data['Fire_occurred'].values,
            month_data[pred_col].values
        )
        
        # Add model prefix
        for key, value in model_metrics.items():
            metrics[f'{model_name}_{key}'] = value
    
    monthly_metrics.append(metrics)

monthly_df = pd.DataFrame(monthly_metrics)
monthly_df = monthly_df.sort_values('Date').reset_index(drop=True)

print(f"Monthly metrics calculated:")
print(f"   Total months: {len(monthly_df)}")
print(f"   Date range: {monthly_df['Date'].min().strftime('%Y-%m')} to {monthly_df['Date'].max().strftime('%Y-%m')}")
print()

# Show sample
print("Sample monthly metrics:")
print(monthly_df[['YearMonth', 'Total_Fires', 'Standard_Precision', 
                  'Standard_Recall', 'Standard_F1']].head(10))
print()

# Save monthly metrics
metrics_file = OUTPUT_DIR / 'monthly_pr_metrics.csv'
monthly_df.to_csv(metrics_file, index=False)
print(f"Saved: {metrics_file}\n")

```


```{python}
# Create Individual Model PR Curves with Fire

# Define fire season highlighting
FIRE_SEASON_MONTHS = [4, 5, 6, 7, 8, 9]  # April to September

for model_name in MODELS_TO_ANALYZE:
    print(f"Creating plot for {model_name}...")
    
    fig, ax1 = plt.subplots(figsize=(18, 8))
    
    ## bar chart of fire counts
    ax2 = ax1.twinx()
    
    # Create color array for fire season highlighting
    bar_colors = ['#ff6b6b' if m in FIRE_SEASON_MONTHS else '#95a5a6' 
                  for m in monthly_df['Month']]
    
    bars = ax2.bar(
        monthly_df['Date'],
        monthly_df['Total_Fires'],
        width=25,  # ~25 days wide
        color=bar_colors,
        alpha=0.3,
        label='Fire Count',
        edgecolor='none'
    )
    
    ax2.set_ylabel('Total Fires (Monthly Count)', fontsize=13, fontweight='bold', color='#e74c3c')
    ax2.tick_params(axis='y', labelcolor='#e74c3c', labelsize=11)
    ax2.spines['right'].set_color('#e74c3c')
    ax2.spines['right'].set_linewidth(2)
    
    # Set y-axis limit for bars
    max_fires = monthly_df['Total_Fires'].max()
    ax2.set_ylim([0, max_fires * 1.15])
    
    


    ## Precision and recall
    precision_col = f'{model_name}_Precision'
    recall_col = f'{model_name}_Recall'
    f1_col = f'{model_name}_F1'
    
    # Plot Precision
    line1 = ax1.plot(
        monthly_df['Date'],
        monthly_df[precision_col],
        marker='o',
        markersize=6,
        linewidth=2.5,
        color='#3498db',
        label='Precision',
        zorder=5
    )
    
    # Plot Recall
    line2 = ax1.plot(
        monthly_df['Date'],
        monthly_df[recall_col],
        marker='s',
        markersize=6,
        linewidth=2.5,
        color='#2ecc71',
        label='Recall',
        zorder=5
    )
    
    # Plot F1-Score
    line3 = ax1.plot(
        monthly_df['Date'],
        monthly_df[f1_col],
        marker='^',
        markersize=6,
        linewidth=2.5,
        color='#9b59b6',
        label='F1-Score',
        linestyle='--',
        zorder=5
    )
    
   

   ## Format
    
    ax1.set_xlabel('Date', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Score (0-1)', fontsize=13, fontweight='bold', color='black')
    ax1.tick_params(axis='y', labelsize=11)
    ax1.set_ylim([0, 1.05])
    
    # X-axis formatting
    ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # Grid
    ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.8, zorder=1)
    ax1.set_axisbelow(True)
    
    # Add horizontal reference lines
    ax1.axhline(y=0.5, color='gray', linestyle=':', linewidth=1.5, alpha=0.5, zorder=2)
    ax1.axhline(y=0.7, color='gray', linestyle=':', linewidth=1.5, alpha=0.5, zorder=2)
    
    ## stats
    avg_precision = monthly_df[precision_col].mean()
    avg_recall = monthly_df[recall_col].mean()
    avg_f1 = monthly_df[f1_col].mean()
    
    # Fire season stats
    fire_season_mask = monthly_df['Month'].isin(FIRE_SEASON_MONTHS)
    fs_precision = monthly_df[fire_season_mask][precision_col].mean()
    fs_recall = monthly_df[fire_season_mask][recall_col].mean()
    fs_f1 = monthly_df[fire_season_mask][f1_col].mean()
    
    title_text = (
        f'{model_name} Model - Temporal Precision-Recall Performance\n'
        f'Overall: Precision={avg_precision:.3f}, Recall={avg_recall:.3f}, F1={avg_f1:.3f} | '
        f'Fire Season: Precision={fs_precision:.3f}, Recall={fs_recall:.3f}, F1={fs_f1:.3f}'
    )
    
    ax1.set_title(title_text, fontsize=15, fontweight='bold', pad=20)
    
    
    # Performance metrics legend
    legend1 = ax1.legend(loc='upper left', fontsize=11, framealpha=0.9,
                        fancybox=True, shadow=True)
    
    # Fire count legend
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#ff6b6b', alpha=0.3, label='Fire Season (Apr-Sep)'),
        Patch(facecolor='#95a5a6', alpha=0.3, label='Non-Fire Season')
    ]
    legend2 = ax2.legend(handles=legend_elements, loc='upper right', 
                        fontsize=11, framealpha=0.9, fancybox=True, shadow=True)
    

    ## Add fire season background shading
    for year in monthly_df['Year'].unique():
        fire_season_start = pd.Timestamp(f'{year}-04-01')
        fire_season_end = pd.Timestamp(f'{year}-09-30')
        
        ax1.axvspan(fire_season_start, fire_season_end, 
                   alpha=0.05, color='red', zorder=0)
  
    plt.tight_layout()
    
    
    plt.show()
```


```{python}
fig, axes = plt.subplots(2, 2, figsize=(20, 14))
axes = axes.flatten()

for idx, model_name in enumerate(MODELS_TO_ANALYZE):
    ax1 = axes[idx]
    ax2 = ax1.twinx()
    
    # Background: Fire count
    bar_colors = ['#ff6b6b' if m in FIRE_SEASON_MONTHS else '#95a5a6' 
                  for m in monthly_df['Month']]
    
    ax2.bar(
        monthly_df['Date'],
        monthly_df['Total_Fires'],
        width=25,
        color=bar_colors,
        alpha=0.25,
        edgecolor='none'
    )
    
    ax2.set_ylabel('Fire Count', fontsize=11, fontweight='bold', color='#e74c3c')
    ax2.tick_params(axis='y', labelcolor='#e74c3c', labelsize=10)
    ax2.set_ylim([0, monthly_df['Total_Fires'].max() * 1.15])
    
    # Foreground: PR curves
    precision_col = f'{model_name}_Precision'
    recall_col = f'{model_name}_Recall'
    f1_col = f'{model_name}_F1'
    
    ax1.plot(monthly_df['Date'], monthly_df[precision_col], 
            marker='o', markersize=4, linewidth=2, color='#3498db', 
            label='Precision', zorder=5)
    
    ax1.plot(monthly_df['Date'], monthly_df[recall_col],
            marker='s', markersize=4, linewidth=2, color='#2ecc71',
            label='Recall', zorder=5)
    
    ax1.plot(monthly_df['Date'], monthly_df[f1_col],
            marker='^', markersize=4, linewidth=2, color='#9b59b6',
            label='F1-Score', linestyle='--', zorder=5)
    
    # Formatting
    ax1.set_ylabel('Score', fontsize=11, fontweight='bold')
    ax1.set_ylim([0, 1.05])
    ax1.grid(True, alpha=0.3, linestyle='--', zorder=1)
    ax1.set_axisbelow(True)
    
    # Reference lines
    ax1.axhline(y=0.5, color='gray', linestyle=':', linewidth=1, alpha=0.4)
    
    # Fire season shading
    for year in monthly_df['Year'].unique():
        ax1.axvspan(pd.Timestamp(f'{year}-04-01'), 
                   pd.Timestamp(f'{year}-09-30'),
                   alpha=0.05, color='red', zorder=0)
    
    # X-axis
    ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # Stats
    avg_p = monthly_df[precision_col].mean()
    avg_r = monthly_df[recall_col].mean()
    avg_f1 = monthly_df[f1_col].mean()
    
    ax1.set_title(
        f'{model_name}\nP={avg_p:.3f}, R={avg_r:.3f}, F1={avg_f1:.3f}',
        fontsize=13, fontweight='bold', pad=15
    )
    
    # Legends
    if idx == 0:
        ax1.legend(loc='upper left', fontsize=9, framealpha=0.9)

fig.suptitle(
    'Temporal Precision-Recall Performance - All Models\n'
    'Monthly Aggregation with Fire Activity Background',
    fontsize=16, fontweight='bold', y=0.995
)

plt.tight_layout()

plt.show()
```


## Output 
```{python}

metric_name = 'Recall'
color = 'black'

fig, ax1 = plt.subplots(1, 1, figsize=(16, 8))
ax2 = ax1.twinx()

# Fire count background
bar_colors = ['#ff6b6b' if m in FIRE_SEASON_MONTHS else '#95a5a6'
              for m in monthly_df['Month']]

ax2.bar(
    monthly_df['Date'],
    monthly_df['Total_Fires'],
    width=25,
    color=bar_colors,
    alpha=0.2,
    edgecolor='none',
    zorder=0
)

ax2.set_ylabel('Fire Count', fontsize=17, fontweight='bold', color='black')
ax2.tick_params(axis='y', labelcolor='black', labelsize=15)
ax2.set_ylim([0, monthly_df['Total_Fires'].max() * 1.15])

# Recall curves
markers = ['o', 's', '^', 'D']
linestyles = ['-', '--', '-.', ':']

for model_idx, model_name in enumerate(MODELS_TO_ANALYZE):
    metric_col = f'{model_name}_{metric_name}'

    ax1.plot(
        monthly_df['Date'],
        monthly_df[metric_col],
        marker=markers[model_idx],
        markersize=6,
        linewidth=3,
        linestyle=linestyles[model_idx],
        label=model_name,
        alpha=0.85,
        zorder=5
    )

# Formatting
ax1.set_ylabel('Recall', fontsize=17, fontweight='bold')
ax1.set_ylim([0, 1.05])
ax1.grid(True, alpha=0.3, linestyle='--')
ax1.set_axisbelow(True)

# Reference line
ax1.axhline(y=0.5, color='gray', linestyle=':', linewidth=1.5, alpha=0.5)

# Fire season shading
for year in monthly_df['Year'].unique():
    ax1.axvspan(
        pd.Timestamp(f'{year}-04-01'),
        pd.Timestamp(f'{year}-09-30'),
        alpha=0.05,
        color='red',
        zorder=0
    )

# X-axis
ax1.set_xlabel('Date', fontsize=17, fontweight='bold')
ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')

ax1.tick_params(axis='both', labelsize=15)


ax1.legend(
    loc='upper left',
    fontsize=17,
    framealpha=0.9,
    fancybox=True,
    shadow=True,
    ncol=4
)

# ax1.set_title(
#     'Temporal Recall Comparison with Monthly Fire Activity',
#     fontsize=20,
#     fontweight='bold',
#     pad=15
# )

plt.tight_layout()

output_file = OUTPUT_DIR / '05_temporal_recall_analysis.png'
plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
print(f"Saved: {output_file}")
```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

```{python}

```

































